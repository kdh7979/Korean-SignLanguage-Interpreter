{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import requests\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\core\\src\\arithm.cpp:250: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'cv::binary_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ee0d824d2cb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m                     \u001b[1;31m#RGB -> binary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                     \u001b[0mROI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mROI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mROI\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m                     \u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbottom\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mh_mask\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbottom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mROI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MediaPipe FaceMesh'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\core\\src\\arithm.cpp:250: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'cv::binary_op'\n"
     ]
    }
   ],
   "source": [
    "# For webcam input:\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "for i in range(1, 2):\n",
    "    cap = cv2.VideoCapture(r\"D:\\DATASET\\1_3000 dataset\\KETI_SL_000000000%d.avi\" %i)\n",
    "    with mp_face_mesh.FaceMesh(min_detection_confidence=0.5,min_tracking_confidence=0.5) as face_mesh:\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                # If loading a video, use 'break' instead of 'continue'.\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "            # the BGR image to RGB.\n",
    "            image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "            # To improve performance, optionally mark the image as not writeable to\n",
    "            # pass by reference.\n",
    "            image.flags.writeable = False\n",
    "            results = face_mesh.process(image)\n",
    "            # Draw the face mesh annotations on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            if results.multi_face_landmarks:\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=image,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACE_CONNECTIONS,\n",
    "                        landmark_drawing_spec=drawing_spec,\n",
    "                        connection_drawing_spec=drawing_spec)\n",
    "                    #4개 랜드마크의 픽셀 좌표 지정\n",
    "                    top = int(results.multi_face_landmarks[0].landmark[10].y*720)\n",
    "                    bottom = int(results.multi_face_landmarks[0].landmark[152].y*720)\n",
    "                    left = int(results.multi_face_landmarks[0].landmark[234].x*1280) - 40\n",
    "                    right = int(results.multi_face_landmarks[0].landmark[454].x*1280) + 40\n",
    "                    #마스크 이미지의 크기 정하기\n",
    "                    h_mask = int((bottom - top)/2)+45\n",
    "                    w_mask = right - left\n",
    "                    #마스크 이미지 로드\n",
    "                    mask = cv2.imread(r\"D:\\DATASET\\mask.png\")\n",
    "                    alpha = cv2.imread(r\"D:\\DATASET\\alpha.png\")\n",
    "                    mask = mask[350:890, 0:1200]\n",
    "                    #마스크 크기 조정\n",
    "                    mask = cv2.resize(mask, (w_mask, h_mask))\n",
    "                    alpha = cv2.resize(alpha, (w_mask, h_mask))\n",
    "                    #ROI 추출\n",
    "                    ROI = image[bottom-h_mask:bottom, left:right]\n",
    "                    #RGB -> binary\n",
    "                    ret, mask = cv2.threshold(alpha, 1, 255, cv2.THRESH_BINARY)\n",
    "                    ROI = cv2.bitwise_and(ROI, ROI, mask = mask)\n",
    "                    image[bottom-h_mask:bottom, left:right] = ROI\n",
    "            cv2.imshow('MediaPipe FaceMesh', image)\n",
    "            if cv2.waitKey(1) & 0xFF == 27:\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.imread(r\"D:\\DATASET\\nmask.png\", cv2.IMREAD_UNCHANGED)\n",
    "*_, alpha = cv2.split(mask)\n",
    "cv2.imwrite(\"n_alpha.png\", alpha)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
